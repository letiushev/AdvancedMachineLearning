{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final2V.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4bc74941710541648ae6ce7befc054b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3e8fa87db26e45f6a3ba37146b03faf4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7950e8878e34d169d5c7e1b35b7fafb",
              "IPY_MODEL_bf82e0b5a0fb4e7b8da63186111f6da5",
              "IPY_MODEL_a450d2f7cd3f44e3be5ff398c20809b2"
            ]
          }
        },
        "3e8fa87db26e45f6a3ba37146b03faf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7950e8878e34d169d5c7e1b35b7fafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9bd12c3d49184364ab0a463112de6215",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4c899ddfc7547668394cbc35d2d50eb"
          }
        },
        "bf82e0b5a0fb4e7b8da63186111f6da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e7e97d0b57d4dc88e88e8bebf13b148",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 136595076,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 136595076,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bb3d287179f24c0a85a513966aaa73d2"
          }
        },
        "a450d2f7cd3f44e3be5ff398c20809b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9af8201a05e64c0d9a8ea689aea16dea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 130M/130M [00:01&lt;00:00, 77.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2308dc125554447eafaf43dffefcf6d8"
          }
        },
        "9bd12c3d49184364ab0a463112de6215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4c899ddfc7547668394cbc35d2d50eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e7e97d0b57d4dc88e88e8bebf13b148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bb3d287179f24c0a85a513966aaa73d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9af8201a05e64c0d9a8ea689aea16dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2308dc125554447eafaf43dffefcf6d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CipXi25ballk"
      },
      "source": [
        "# Faster R - CNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLThmV7gcgxD"
      },
      "source": [
        "## Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI-YvIP-00Y3",
        "outputId": "4eea2e46-367f-437b-b240-9a1fc96263ed"
      },
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "torch:  1.10 ; cuda:  cu111\n",
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n",
            "Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n",
            "Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.1)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n",
            "Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.1)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20211023)\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.62.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (3.10.0.2)\n",
            "Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n",
            "Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.5.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.4.3)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n",
            "Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.9.0)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (2021.11.10)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (5.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.4.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (4.8)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.3.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2) (57.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2) (3.6.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.42.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.8.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqI9EInwc0Zv"
      },
      "source": [
        "## Basic setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwMJJDwa03x2"
      },
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLSmOpaYdhNs"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2NHQRL01Byd",
        "outputId": "0c685f1c-ec80-460f-d628-2102552d0d1d"
      },
      "source": [
        "!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "!unzip val2017.zip > /dev/null"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 16:55:51--  http://images.cocodataset.org/zips/val2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.161.121\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.161.121|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 815585330 (778M) [application/zip]\n",
            "Saving to: ‘val2017.zip’\n",
            "\n",
            "val2017.zip         100%[===================>] 777.80M  95.4MB/s    in 8.3s    \n",
            "\n",
            "2021-11-26 16:55:59 (93.2 MB/s) - ‘val2017.zip’ saved [815585330/815585330]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opIIoC1EdnyL"
      },
      "source": [
        "## Download annotations for Coco dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GZGPxAd1IFV",
        "outputId": "99a88c0e-a117-4d0f-ee33-20e8e2a42fcc"
      },
      "source": [
        " !wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        " !unzip annotations_trainval2017.zip > /dev/null"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 16:56:13--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.129.251\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.129.251|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252907541 (241M) [application/zip]\n",
            "Saving to: ‘annotations_trainval2017.zip’\n",
            "\n",
            "annotations_trainva 100%[===================>] 241.19M  88.4MB/s    in 2.7s    \n",
            "\n",
            "2021-11-26 16:56:16 (88.4 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXSyBbWOeKTp"
      },
      "source": [
        "## Register Coco dataset to detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NinobK4c1SMe"
      },
      "source": [
        "from detectron2.data.datasets import register_coco_instances\n",
        "register_coco_instances(\"my_dataset\", {}, \"/content/annotations/instances_val2017.json\", \"/content/val2017\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzNpzL7peXfg"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkG4yt_nebgj"
      },
      "source": [
        "We are doing it in order to receive model_final.pth file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmOTtiEk3s-8",
        "outputId": "900b93d4-0de6-47b8-ab61-b9c47149728a"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # faster, and good enough for this toy dataset (default: 512)\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 80\n",
        "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/26 16:57:42 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/26 16:57:42 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[11/26 16:57:42 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from /content/annotations/instances_val2017.json\n",
            "\u001b[32m[11/26 16:57:43 d2.data.build]: \u001b[0mRemoved 48 images with no usable annotations. 4952 images left.\n",
            "\u001b[32m[11/26 16:57:43 d2.data.build]: \u001b[0mDistribution of instances among all 80 categories:\n",
            "\u001b[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |\n",
            "|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|\n",
            "|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |\n",
            "|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |\n",
            "|     train     | 190          |    truck     | 414          |     boat      | 424          |\n",
            "| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |\n",
            "| parking meter | 60           |    bench     | 411          |     bird      | 427          |\n",
            "|      cat      | 202          |     dog      | 218          |     horse     | 272          |\n",
            "|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |\n",
            "|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |\n",
            "|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |\n",
            "|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |\n",
            "|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |\n",
            "|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |\n",
            "|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |\n",
            "|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |\n",
            "|     fork      | 215          |    knife     | 325          |     spoon     | 253          |\n",
            "|     bowl      | 623          |    banana    | 370          |     apple     | 236          |\n",
            "|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |\n",
            "|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |\n",
            "|     donut     | 328          |     cake     | 310          |     chair     | 1771         |\n",
            "|     couch     | 261          | potted plant | 342          |      bed      | 163          |\n",
            "| dining table  | 695          |    toilet    | 179          |      tv       | 288          |\n",
            "|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |\n",
            "|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |\n",
            "|     oven      | 143          |   toaster    | 9            |     sink      | 225          |\n",
            "| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |\n",
            "|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |\n",
            "|  hair drier   | 11           |  toothbrush  | 57           |               |              |\n",
            "|     total     | 36335        |              |              |               |              |\u001b[0m\n",
            "\u001b[32m[11/26 16:57:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[11/26 16:57:43 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[11/26 16:57:43 d2.data.common]: \u001b[0mSerializing 4952 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[11/26 16:57:43 d2.data.common]: \u001b[0mSerialized dataset takes 19.07 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_280758.pkl: 167MB [00:06, 26.7MB/s]                           \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/26 16:57:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n",
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/26 16:58:21 d2.utils.events]: \u001b[0m eta: 0:05:56  iter: 19  total_loss: 0.5201  loss_cls: 0.1766  loss_box_reg: 0.2324  loss_rpn_cls: 0.01863  loss_rpn_loc: 0.03851  time: 1.2584  data_time: 0.0240  lr: 1.6068e-05  max_mem: 2554M\n",
            "\u001b[32m[11/26 16:58:46 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 39  total_loss: 0.6324  loss_cls: 0.1829  loss_box_reg: 0.2445  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.04908  time: 1.2483  data_time: 0.0125  lr: 3.2718e-05  max_mem: 2554M\n",
            "\u001b[32m[11/26 16:59:11 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 59  total_loss: 0.5408  loss_cls: 0.1907  loss_box_reg: 0.2535  loss_rpn_cls: 0.02146  loss_rpn_loc: 0.04879  time: 1.2488  data_time: 0.0081  lr: 4.9367e-05  max_mem: 2643M\n",
            "\u001b[32m[11/26 16:59:37 d2.utils.events]: \u001b[0m eta: 0:04:41  iter: 79  total_loss: 0.5164  loss_cls: 0.1916  loss_box_reg: 0.2406  loss_rpn_cls: 0.04338  loss_rpn_loc: 0.05476  time: 1.2649  data_time: 0.0127  lr: 6.6017e-05  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:00:02 d2.utils.events]: \u001b[0m eta: 0:04:14  iter: 99  total_loss: 0.7916  loss_cls: 0.2444  loss_box_reg: 0.2945  loss_rpn_cls: 0.02981  loss_rpn_loc: 0.05152  time: 1.2579  data_time: 0.0091  lr: 8.2668e-05  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:00:27 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 119  total_loss: 0.4965  loss_cls: 0.1656  loss_box_reg: 0.2257  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.03725  time: 1.2588  data_time: 0.0104  lr: 9.9318e-05  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:00:53 d2.utils.events]: \u001b[0m eta: 0:03:25  iter: 139  total_loss: 0.4925  loss_cls: 0.1587  loss_box_reg: 0.1864  loss_rpn_cls: 0.02784  loss_rpn_loc: 0.05116  time: 1.2668  data_time: 0.0116  lr: 0.00011597  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:01:18 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 159  total_loss: 0.4866  loss_cls: 0.1869  loss_box_reg: 0.2246  loss_rpn_cls: 0.02229  loss_rpn_loc: 0.02363  time: 1.2621  data_time: 0.0117  lr: 0.00013262  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:01:43 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 179  total_loss: 0.397  loss_cls: 0.1473  loss_box_reg: 0.1911  loss_rpn_cls: 0.01928  loss_rpn_loc: 0.03114  time: 1.2639  data_time: 0.0109  lr: 0.00014927  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:02:10 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 199  total_loss: 0.5565  loss_cls: 0.2351  loss_box_reg: 0.2424  loss_rpn_cls: 0.03015  loss_rpn_loc: 0.05652  time: 1.2698  data_time: 0.0114  lr: 0.00016592  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:02:36 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 219  total_loss: 0.6208  loss_cls: 0.2315  loss_box_reg: 0.278  loss_rpn_cls: 0.03908  loss_rpn_loc: 0.06873  time: 1.2714  data_time: 0.0110  lr: 0.00018257  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:03:02 d2.utils.events]: \u001b[0m eta: 0:01:17  iter: 239  total_loss: 0.4811  loss_cls: 0.2272  loss_box_reg: 0.1939  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.05251  time: 1.2767  data_time: 0.0123  lr: 0.00019922  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:03:28 d2.utils.events]: \u001b[0m eta: 0:00:51  iter: 259  total_loss: 0.5327  loss_cls: 0.2212  loss_box_reg: 0.2588  loss_rpn_cls: 0.02659  loss_rpn_loc: 0.03973  time: 1.2772  data_time: 0.0096  lr: 0.00021587  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:03:55 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 279  total_loss: 0.4898  loss_cls: 0.1957  loss_box_reg: 0.2396  loss_rpn_cls: 0.02476  loss_rpn_loc: 0.03714  time: 1.2808  data_time: 0.0096  lr: 0.00023252  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:04:20 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.5229  loss_cls: 0.1866  loss_box_reg: 0.2311  loss_rpn_cls: 0.05797  loss_rpn_loc: 0.04629  time: 1.2798  data_time: 0.0084  lr: 0.00024917  max_mem: 2734M\n",
            "\u001b[32m[11/26 17:04:21 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:06:21 (1.2798 s / it)\n",
            "\u001b[32m[11/26 17:04:21 d2.engine.hooks]: \u001b[0mTotal training time: 0:06:22 (0:00:01 on hooks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V7CzbTQAl95"
      },
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") \n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfAAaUhofDna"
      },
      "source": [
        "## Evaluate the performance by using AP metric implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4fl9SbKBNui",
        "outputId": "6b171cbc-dfef-41e8-f468-cbc1a9335b54"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"my_dataset\", output_dir=\"./output\")\n",
        "val_loader = build_detection_test_loader(cfg, \"my_dataset\")\n",
        "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/26 17:04:57 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[11/26 17:04:58 d2.data.datasets.coco]: \u001b[0mLoaded 5000 images in COCO format from /content/annotations/instances_val2017.json\n",
            "\u001b[32m[11/26 17:04:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[11/26 17:04:58 d2.data.common]: \u001b[0mSerializing 5000 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[11/26 17:04:59 d2.data.common]: \u001b[0mSerialized dataset takes 19.07 MiB\n",
            "\u001b[32m[11/26 17:04:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 5000 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  max_size = (max_size + (stride - 1)) // stride * stride\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[11/26 17:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 11/5000. Dataloading: 0.0018 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3295 s/iter. ETA=0:27:23\n",
            "\u001b[32m[11/26 17:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 27/5000. Dataloading: 0.0023 s/iter. Inference: 0.3247 s/iter. Eval: 0.0004 s/iter. Total: 0.3276 s/iter. ETA=0:27:09\n",
            "\u001b[32m[11/26 17:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 43/5000. Dataloading: 0.0023 s/iter. Inference: 0.3264 s/iter. Eval: 0.0003 s/iter. Total: 0.3293 s/iter. ETA=0:27:12\n",
            "\u001b[32m[11/26 17:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 59/5000. Dataloading: 0.0023 s/iter. Inference: 0.3268 s/iter. Eval: 0.0003 s/iter. Total: 0.3297 s/iter. ETA=0:27:08\n",
            "\u001b[32m[11/26 17:05:23 d2.evaluation.evaluator]: \u001b[0mInference done 74/5000. Dataloading: 0.0023 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:27:09\n",
            "\u001b[32m[11/26 17:05:29 d2.evaluation.evaluator]: \u001b[0mInference done 90/5000. Dataloading: 0.0025 s/iter. Inference: 0.3260 s/iter. Eval: 0.0003 s/iter. Total: 0.3291 s/iter. ETA=0:26:55\n",
            "\u001b[32m[11/26 17:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 106/5000. Dataloading: 0.0025 s/iter. Inference: 0.3246 s/iter. Eval: 0.0003 s/iter. Total: 0.3277 s/iter. ETA=0:26:43\n",
            "\u001b[32m[11/26 17:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 122/5000. Dataloading: 0.0025 s/iter. Inference: 0.3249 s/iter. Eval: 0.0003 s/iter. Total: 0.3280 s/iter. ETA=0:26:40\n",
            "\u001b[32m[11/26 17:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 137/5000. Dataloading: 0.0025 s/iter. Inference: 0.3259 s/iter. Eval: 0.0003 s/iter. Total: 0.3290 s/iter. ETA=0:26:39\n",
            "\u001b[32m[11/26 17:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 152/5000. Dataloading: 0.0026 s/iter. Inference: 0.3270 s/iter. Eval: 0.0003 s/iter. Total: 0.3302 s/iter. ETA=0:26:40\n",
            "\u001b[32m[11/26 17:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 168/5000. Dataloading: 0.0027 s/iter. Inference: 0.3265 s/iter. Eval: 0.0003 s/iter. Total: 0.3297 s/iter. ETA=0:26:33\n",
            "\u001b[32m[11/26 17:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 184/5000. Dataloading: 0.0027 s/iter. Inference: 0.3266 s/iter. Eval: 0.0003 s/iter. Total: 0.3298 s/iter. ETA=0:26:28\n",
            "\u001b[32m[11/26 17:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 200/5000. Dataloading: 0.0027 s/iter. Inference: 0.3267 s/iter. Eval: 0.0003 s/iter. Total: 0.3300 s/iter. ETA=0:26:23\n",
            "\u001b[32m[11/26 17:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 216/5000. Dataloading: 0.0027 s/iter. Inference: 0.3267 s/iter. Eval: 0.0003 s/iter. Total: 0.3299 s/iter. ETA=0:26:18\n",
            "\u001b[32m[11/26 17:06:16 d2.evaluation.evaluator]: \u001b[0mInference done 232/5000. Dataloading: 0.0027 s/iter. Inference: 0.3266 s/iter. Eval: 0.0003 s/iter. Total: 0.3298 s/iter. ETA=0:26:12\n",
            "\u001b[32m[11/26 17:06:21 d2.evaluation.evaluator]: \u001b[0mInference done 247/5000. Dataloading: 0.0027 s/iter. Inference: 0.3270 s/iter. Eval: 0.0003 s/iter. Total: 0.3302 s/iter. ETA=0:26:09\n",
            "\u001b[32m[11/26 17:06:26 d2.evaluation.evaluator]: \u001b[0mInference done 262/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:26:06\n",
            "\u001b[32m[11/26 17:06:31 d2.evaluation.evaluator]: \u001b[0mInference done 278/5000. Dataloading: 0.0026 s/iter. Inference: 0.3269 s/iter. Eval: 0.0003 s/iter. Total: 0.3300 s/iter. ETA=0:25:58\n",
            "\u001b[32m[11/26 17:06:36 d2.evaluation.evaluator]: \u001b[0mInference done 293/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:25:55\n",
            "\u001b[32m[11/26 17:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 309/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:25:50\n",
            "\u001b[32m[11/26 17:06:46 d2.evaluation.evaluator]: \u001b[0mInference done 325/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:25:44\n",
            "\u001b[32m[11/26 17:06:51 d2.evaluation.evaluator]: \u001b[0mInference done 340/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:25:41\n",
            "\u001b[32m[11/26 17:06:56 d2.evaluation.evaluator]: \u001b[0mInference done 355/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:25:37\n",
            "\u001b[32m[11/26 17:07:02 d2.evaluation.evaluator]: \u001b[0mInference done 371/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3312 s/iter. ETA=0:25:32\n",
            "\u001b[32m[11/26 17:07:07 d2.evaluation.evaluator]: \u001b[0mInference done 387/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:25:25\n",
            "\u001b[32m[11/26 17:07:12 d2.evaluation.evaluator]: \u001b[0mInference done 403/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:25:19\n",
            "\u001b[32m[11/26 17:07:17 d2.evaluation.evaluator]: \u001b[0mInference done 419/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:25:13\n",
            "\u001b[32m[11/26 17:07:22 d2.evaluation.evaluator]: \u001b[0mInference done 434/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:25:09\n",
            "\u001b[32m[11/26 17:07:28 d2.evaluation.evaluator]: \u001b[0mInference done 450/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:25:03\n",
            "\u001b[32m[11/26 17:07:33 d2.evaluation.evaluator]: \u001b[0mInference done 465/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:24:58\n",
            "\u001b[32m[11/26 17:07:38 d2.evaluation.evaluator]: \u001b[0mInference done 480/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:24:55\n",
            "\u001b[32m[11/26 17:07:43 d2.evaluation.evaluator]: \u001b[0mInference done 495/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:24:51\n",
            "\u001b[32m[11/26 17:07:48 d2.evaluation.evaluator]: \u001b[0mInference done 511/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:24:44\n",
            "\u001b[32m[11/26 17:07:53 d2.evaluation.evaluator]: \u001b[0mInference done 527/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:24:39\n",
            "\u001b[32m[11/26 17:07:59 d2.evaluation.evaluator]: \u001b[0mInference done 543/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:24:34\n",
            "\u001b[32m[11/26 17:08:04 d2.evaluation.evaluator]: \u001b[0mInference done 559/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:24:28\n",
            "\u001b[32m[11/26 17:08:09 d2.evaluation.evaluator]: \u001b[0mInference done 575/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:24:23\n",
            "\u001b[32m[11/26 17:08:14 d2.evaluation.evaluator]: \u001b[0mInference done 591/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:24:17\n",
            "\u001b[32m[11/26 17:08:20 d2.evaluation.evaluator]: \u001b[0mInference done 607/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:24:11\n",
            "\u001b[32m[11/26 17:08:25 d2.evaluation.evaluator]: \u001b[0mInference done 622/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:24:07\n",
            "\u001b[32m[11/26 17:08:30 d2.evaluation.evaluator]: \u001b[0mInference done 637/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:24:03\n",
            "\u001b[32m[11/26 17:08:35 d2.evaluation.evaluator]: \u001b[0mInference done 653/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:23:56\n",
            "\u001b[32m[11/26 17:08:40 d2.evaluation.evaluator]: \u001b[0mInference done 669/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:23:52\n",
            "\u001b[32m[11/26 17:08:45 d2.evaluation.evaluator]: \u001b[0mInference done 684/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:23:48\n",
            "\u001b[32m[11/26 17:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 700/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:23:42\n",
            "\u001b[32m[11/26 17:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 715/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:23:38\n",
            "\u001b[32m[11/26 17:09:01 d2.evaluation.evaluator]: \u001b[0mInference done 731/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:23:32\n",
            "\u001b[32m[11/26 17:09:06 d2.evaluation.evaluator]: \u001b[0mInference done 747/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:23:27\n",
            "\u001b[32m[11/26 17:09:11 d2.evaluation.evaluator]: \u001b[0mInference done 762/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:23:22\n",
            "\u001b[32m[11/26 17:09:17 d2.evaluation.evaluator]: \u001b[0mInference done 778/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:23:17\n",
            "\u001b[32m[11/26 17:09:22 d2.evaluation.evaluator]: \u001b[0mInference done 793/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:23:12\n",
            "\u001b[32m[11/26 17:09:27 d2.evaluation.evaluator]: \u001b[0mInference done 808/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3313 s/iter. ETA=0:23:08\n",
            "\u001b[32m[11/26 17:09:32 d2.evaluation.evaluator]: \u001b[0mInference done 824/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:23:02\n",
            "\u001b[32m[11/26 17:09:37 d2.evaluation.evaluator]: \u001b[0mInference done 840/5000. Dataloading: 0.0026 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:57\n",
            "\u001b[32m[11/26 17:09:42 d2.evaluation.evaluator]: \u001b[0mInference done 855/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:52\n",
            "\u001b[32m[11/26 17:09:47 d2.evaluation.evaluator]: \u001b[0mInference done 871/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3312 s/iter. ETA=0:22:47\n",
            "\u001b[32m[11/26 17:09:53 d2.evaluation.evaluator]: \u001b[0mInference done 887/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3312 s/iter. ETA=0:22:42\n",
            "\u001b[32m[11/26 17:09:58 d2.evaluation.evaluator]: \u001b[0mInference done 903/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:36\n",
            "\u001b[32m[11/26 17:10:03 d2.evaluation.evaluator]: \u001b[0mInference done 919/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:22:30\n",
            "\u001b[32m[11/26 17:10:08 d2.evaluation.evaluator]: \u001b[0mInference done 935/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:22:25\n",
            "\u001b[32m[11/26 17:10:14 d2.evaluation.evaluator]: \u001b[0mInference done 950/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:20\n",
            "\u001b[32m[11/26 17:10:19 d2.evaluation.evaluator]: \u001b[0mInference done 965/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:16\n",
            "\u001b[32m[11/26 17:10:24 d2.evaluation.evaluator]: \u001b[0mInference done 981/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:10\n",
            "\u001b[32m[11/26 17:10:29 d2.evaluation.evaluator]: \u001b[0mInference done 997/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:22:05\n",
            "\u001b[32m[11/26 17:10:34 d2.evaluation.evaluator]: \u001b[0mInference done 1013/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:21:59\n",
            "\u001b[32m[11/26 17:10:39 d2.evaluation.evaluator]: \u001b[0mInference done 1029/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:21:54\n",
            "\u001b[32m[11/26 17:10:45 d2.evaluation.evaluator]: \u001b[0mInference done 1045/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:21:48\n",
            "\u001b[32m[11/26 17:10:50 d2.evaluation.evaluator]: \u001b[0mInference done 1060/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:21:43\n",
            "\u001b[32m[11/26 17:10:55 d2.evaluation.evaluator]: \u001b[0mInference done 1075/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:21:39\n",
            "\u001b[32m[11/26 17:11:00 d2.evaluation.evaluator]: \u001b[0mInference done 1091/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:21:34\n",
            "\u001b[32m[11/26 17:11:06 d2.evaluation.evaluator]: \u001b[0mInference done 1107/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:21:28\n",
            "\u001b[32m[11/26 17:11:11 d2.evaluation.evaluator]: \u001b[0mInference done 1122/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:21:24\n",
            "\u001b[32m[11/26 17:11:16 d2.evaluation.evaluator]: \u001b[0mInference done 1137/5000. Dataloading: 0.0027 s/iter. Inference: 0.3281 s/iter. Eval: 0.0003 s/iter. Total: 0.3314 s/iter. ETA=0:21:20\n",
            "\u001b[32m[11/26 17:11:21 d2.evaluation.evaluator]: \u001b[0mInference done 1153/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3312 s/iter. ETA=0:21:14\n",
            "\u001b[32m[11/26 17:11:26 d2.evaluation.evaluator]: \u001b[0mInference done 1168/5000. Dataloading: 0.0027 s/iter. Inference: 0.3282 s/iter. Eval: 0.0003 s/iter. Total: 0.3314 s/iter. ETA=0:21:09\n",
            "\u001b[32m[11/26 17:11:31 d2.evaluation.evaluator]: \u001b[0mInference done 1184/5000. Dataloading: 0.0027 s/iter. Inference: 0.3282 s/iter. Eval: 0.0003 s/iter. Total: 0.3314 s/iter. ETA=0:21:04\n",
            "\u001b[32m[11/26 17:11:37 d2.evaluation.evaluator]: \u001b[0mInference done 1200/5000. Dataloading: 0.0027 s/iter. Inference: 0.3282 s/iter. Eval: 0.0003 s/iter. Total: 0.3314 s/iter. ETA=0:20:59\n",
            "\u001b[32m[11/26 17:11:42 d2.evaluation.evaluator]: \u001b[0mInference done 1216/5000. Dataloading: 0.0027 s/iter. Inference: 0.3281 s/iter. Eval: 0.0003 s/iter. Total: 0.3313 s/iter. ETA=0:20:53\n",
            "\u001b[32m[11/26 17:11:47 d2.evaluation.evaluator]: \u001b[0mInference done 1231/5000. Dataloading: 0.0027 s/iter. Inference: 0.3281 s/iter. Eval: 0.0003 s/iter. Total: 0.3313 s/iter. ETA=0:20:48\n",
            "\u001b[32m[11/26 17:11:52 d2.evaluation.evaluator]: \u001b[0mInference done 1247/5000. Dataloading: 0.0027 s/iter. Inference: 0.3281 s/iter. Eval: 0.0003 s/iter. Total: 0.3313 s/iter. ETA=0:20:43\n",
            "\u001b[32m[11/26 17:11:57 d2.evaluation.evaluator]: \u001b[0mInference done 1263/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3313 s/iter. ETA=0:20:37\n",
            "\u001b[32m[11/26 17:12:03 d2.evaluation.evaluator]: \u001b[0mInference done 1279/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3312 s/iter. ETA=0:20:32\n",
            "\u001b[32m[11/26 17:12:08 d2.evaluation.evaluator]: \u001b[0mInference done 1294/5000. Dataloading: 0.0027 s/iter. Inference: 0.3280 s/iter. Eval: 0.0003 s/iter. Total: 0.3312 s/iter. ETA=0:20:27\n",
            "\u001b[32m[11/26 17:12:13 d2.evaluation.evaluator]: \u001b[0mInference done 1310/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:20:21\n",
            "\u001b[32m[11/26 17:12:18 d2.evaluation.evaluator]: \u001b[0mInference done 1326/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:20:16\n",
            "\u001b[32m[11/26 17:12:23 d2.evaluation.evaluator]: \u001b[0mInference done 1341/5000. Dataloading: 0.0027 s/iter. Inference: 0.3279 s/iter. Eval: 0.0003 s/iter. Total: 0.3311 s/iter. ETA=0:20:11\n",
            "\u001b[32m[11/26 17:12:28 d2.evaluation.evaluator]: \u001b[0mInference done 1357/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:20:05\n",
            "\u001b[32m[11/26 17:12:33 d2.evaluation.evaluator]: \u001b[0mInference done 1373/5000. Dataloading: 0.0027 s/iter. Inference: 0.3278 s/iter. Eval: 0.0003 s/iter. Total: 0.3310 s/iter. ETA=0:20:00\n",
            "\u001b[32m[11/26 17:12:39 d2.evaluation.evaluator]: \u001b[0mInference done 1389/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:19:54\n",
            "\u001b[32m[11/26 17:12:44 d2.evaluation.evaluator]: \u001b[0mInference done 1404/5000. Dataloading: 0.0027 s/iter. Inference: 0.3277 s/iter. Eval: 0.0003 s/iter. Total: 0.3309 s/iter. ETA=0:19:50\n",
            "\u001b[32m[11/26 17:12:49 d2.evaluation.evaluator]: \u001b[0mInference done 1420/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:19:44\n",
            "\u001b[32m[11/26 17:12:54 d2.evaluation.evaluator]: \u001b[0mInference done 1436/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:19:38\n",
            "\u001b[32m[11/26 17:12:59 d2.evaluation.evaluator]: \u001b[0mInference done 1451/5000. Dataloading: 0.0027 s/iter. Inference: 0.3276 s/iter. Eval: 0.0003 s/iter. Total: 0.3308 s/iter. ETA=0:19:34\n",
            "\u001b[32m[11/26 17:13:04 d2.evaluation.evaluator]: \u001b[0mInference done 1467/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:19:28\n",
            "\u001b[32m[11/26 17:13:09 d2.evaluation.evaluator]: \u001b[0mInference done 1483/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:19:22\n",
            "\u001b[32m[11/26 17:13:15 d2.evaluation.evaluator]: \u001b[0mInference done 1499/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:19:17\n",
            "\u001b[32m[11/26 17:13:20 d2.evaluation.evaluator]: \u001b[0mInference done 1515/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:19:11\n",
            "\u001b[32m[11/26 17:13:25 d2.evaluation.evaluator]: \u001b[0mInference done 1531/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:19:06\n",
            "\u001b[32m[11/26 17:13:30 d2.evaluation.evaluator]: \u001b[0mInference done 1546/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:19:01\n",
            "\u001b[32m[11/26 17:13:35 d2.evaluation.evaluator]: \u001b[0mInference done 1562/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:18:56\n",
            "\u001b[32m[11/26 17:13:41 d2.evaluation.evaluator]: \u001b[0mInference done 1578/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:18:51\n",
            "\u001b[32m[11/26 17:13:46 d2.evaluation.evaluator]: \u001b[0mInference done 1593/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:46\n",
            "\u001b[32m[11/26 17:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 1609/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:41\n",
            "\u001b[32m[11/26 17:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 1625/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:35\n",
            "\u001b[32m[11/26 17:14:02 d2.evaluation.evaluator]: \u001b[0mInference done 1641/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:30\n",
            "\u001b[32m[11/26 17:14:07 d2.evaluation.evaluator]: \u001b[0mInference done 1657/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:25\n",
            "\u001b[32m[11/26 17:14:12 d2.evaluation.evaluator]: \u001b[0mInference done 1673/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:19\n",
            "\u001b[32m[11/26 17:14:17 d2.evaluation.evaluator]: \u001b[0mInference done 1689/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:14\n",
            "\u001b[32m[11/26 17:14:22 d2.evaluation.evaluator]: \u001b[0mInference done 1704/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:18:09\n",
            "\u001b[32m[11/26 17:14:28 d2.evaluation.evaluator]: \u001b[0mInference done 1720/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:18:04\n",
            "\u001b[32m[11/26 17:14:33 d2.evaluation.evaluator]: \u001b[0mInference done 1736/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:58\n",
            "\u001b[32m[11/26 17:14:38 d2.evaluation.evaluator]: \u001b[0mInference done 1751/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:17:54\n",
            "\u001b[32m[11/26 17:14:43 d2.evaluation.evaluator]: \u001b[0mInference done 1767/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:17:48\n",
            "\u001b[32m[11/26 17:14:48 d2.evaluation.evaluator]: \u001b[0mInference done 1783/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:43\n",
            "\u001b[32m[11/26 17:14:54 d2.evaluation.evaluator]: \u001b[0mInference done 1799/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:37\n",
            "\u001b[32m[11/26 17:14:59 d2.evaluation.evaluator]: \u001b[0mInference done 1815/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:32\n",
            "\u001b[32m[11/26 17:15:04 d2.evaluation.evaluator]: \u001b[0mInference done 1831/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:27\n",
            "\u001b[32m[11/26 17:15:09 d2.evaluation.evaluator]: \u001b[0mInference done 1847/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:17:21\n",
            "\u001b[32m[11/26 17:15:15 d2.evaluation.evaluator]: \u001b[0mInference done 1863/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:16\n",
            "\u001b[32m[11/26 17:15:20 d2.evaluation.evaluator]: \u001b[0mInference done 1878/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:11\n",
            "\u001b[32m[11/26 17:15:25 d2.evaluation.evaluator]: \u001b[0mInference done 1894/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:06\n",
            "\u001b[32m[11/26 17:15:30 d2.evaluation.evaluator]: \u001b[0mInference done 1909/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:17:01\n",
            "\u001b[32m[11/26 17:15:35 d2.evaluation.evaluator]: \u001b[0mInference done 1925/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:56\n",
            "\u001b[32m[11/26 17:15:41 d2.evaluation.evaluator]: \u001b[0mInference done 1941/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:51\n",
            "\u001b[32m[11/26 17:15:46 d2.evaluation.evaluator]: \u001b[0mInference done 1957/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:45\n",
            "\u001b[32m[11/26 17:15:51 d2.evaluation.evaluator]: \u001b[0mInference done 1973/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:40\n",
            "\u001b[32m[11/26 17:15:56 d2.evaluation.evaluator]: \u001b[0mInference done 1989/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:35\n",
            "\u001b[32m[11/26 17:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 2005/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:29\n",
            "\u001b[32m[11/26 17:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 2020/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:16:25\n",
            "\u001b[32m[11/26 17:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 2036/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:19\n",
            "\u001b[32m[11/26 17:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 2052/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:16:14\n",
            "\u001b[32m[11/26 17:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 2067/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:09\n",
            "\u001b[32m[11/26 17:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 2083/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:16:03\n",
            "\u001b[32m[11/26 17:16:33 d2.evaluation.evaluator]: \u001b[0mInference done 2099/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:58\n",
            "\u001b[32m[11/26 17:16:38 d2.evaluation.evaluator]: \u001b[0mInference done 2115/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:53\n",
            "\u001b[32m[11/26 17:16:43 d2.evaluation.evaluator]: \u001b[0mInference done 2131/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:47\n",
            "\u001b[32m[11/26 17:16:48 d2.evaluation.evaluator]: \u001b[0mInference done 2147/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:42\n",
            "\u001b[32m[11/26 17:16:54 d2.evaluation.evaluator]: \u001b[0mInference done 2163/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:15:37\n",
            "\u001b[32m[11/26 17:16:59 d2.evaluation.evaluator]: \u001b[0mInference done 2179/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:15:31\n",
            "\u001b[32m[11/26 17:17:04 d2.evaluation.evaluator]: \u001b[0mInference done 2195/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:15:26\n",
            "\u001b[32m[11/26 17:17:09 d2.evaluation.evaluator]: \u001b[0mInference done 2211/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:15:21\n",
            "\u001b[32m[11/26 17:17:14 d2.evaluation.evaluator]: \u001b[0mInference done 2226/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:16\n",
            "\u001b[32m[11/26 17:17:19 d2.evaluation.evaluator]: \u001b[0mInference done 2241/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:11\n",
            "\u001b[32m[11/26 17:17:24 d2.evaluation.evaluator]: \u001b[0mInference done 2256/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:15:06\n",
            "\u001b[32m[11/26 17:17:29 d2.evaluation.evaluator]: \u001b[0mInference done 2271/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:15:01\n",
            "\u001b[32m[11/26 17:17:35 d2.evaluation.evaluator]: \u001b[0mInference done 2286/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:56\n",
            "\u001b[32m[11/26 17:17:40 d2.evaluation.evaluator]: \u001b[0mInference done 2302/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:51\n",
            "\u001b[32m[11/26 17:17:45 d2.evaluation.evaluator]: \u001b[0mInference done 2318/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:46\n",
            "\u001b[32m[11/26 17:17:50 d2.evaluation.evaluator]: \u001b[0mInference done 2334/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:14:40\n",
            "\u001b[32m[11/26 17:17:55 d2.evaluation.evaluator]: \u001b[0mInference done 2349/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:36\n",
            "\u001b[32m[11/26 17:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 2365/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:30\n",
            "\u001b[32m[11/26 17:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 2381/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:14:25\n",
            "\u001b[32m[11/26 17:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 2397/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:20\n",
            "\u001b[32m[11/26 17:18:16 d2.evaluation.evaluator]: \u001b[0mInference done 2413/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:14\n",
            "\u001b[32m[11/26 17:18:22 d2.evaluation.evaluator]: \u001b[0mInference done 2429/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:09\n",
            "\u001b[32m[11/26 17:18:27 d2.evaluation.evaluator]: \u001b[0mInference done 2444/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:14:04\n",
            "\u001b[32m[11/26 17:18:32 d2.evaluation.evaluator]: \u001b[0mInference done 2459/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:13:59\n",
            "\u001b[32m[11/26 17:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 2475/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:13:54\n",
            "\u001b[32m[11/26 17:18:42 d2.evaluation.evaluator]: \u001b[0mInference done 2491/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:13:49\n",
            "\u001b[32m[11/26 17:18:47 d2.evaluation.evaluator]: \u001b[0mInference done 2507/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:13:43\n",
            "\u001b[32m[11/26 17:18:53 d2.evaluation.evaluator]: \u001b[0mInference done 2523/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:13:38\n",
            "\u001b[32m[11/26 17:18:58 d2.evaluation.evaluator]: \u001b[0mInference done 2539/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:13:33\n",
            "\u001b[32m[11/26 17:19:03 d2.evaluation.evaluator]: \u001b[0mInference done 2554/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:13:28\n",
            "\u001b[32m[11/26 17:19:08 d2.evaluation.evaluator]: \u001b[0mInference done 2570/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:13:22\n",
            "\u001b[32m[11/26 17:19:13 d2.evaluation.evaluator]: \u001b[0mInference done 2586/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:13:17\n",
            "\u001b[32m[11/26 17:19:18 d2.evaluation.evaluator]: \u001b[0mInference done 2602/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:13:12\n",
            "\u001b[32m[11/26 17:19:24 d2.evaluation.evaluator]: \u001b[0mInference done 2617/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:13:07\n",
            "\u001b[32m[11/26 17:19:29 d2.evaluation.evaluator]: \u001b[0mInference done 2633/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:13:01\n",
            "\u001b[32m[11/26 17:19:34 d2.evaluation.evaluator]: \u001b[0mInference done 2648/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:57\n",
            "\u001b[32m[11/26 17:19:39 d2.evaluation.evaluator]: \u001b[0mInference done 2663/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:52\n",
            "\u001b[32m[11/26 17:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 2678/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:47\n",
            "\u001b[32m[11/26 17:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 2693/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:12:42\n",
            "\u001b[32m[11/26 17:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 2708/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:12:37\n",
            "\u001b[32m[11/26 17:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 2724/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:12:32\n",
            "\u001b[32m[11/26 17:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 2740/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:26\n",
            "\u001b[32m[11/26 17:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 2756/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:21\n",
            "\u001b[32m[11/26 17:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 2772/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:16\n",
            "\u001b[32m[11/26 17:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 2787/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:11\n",
            "\u001b[32m[11/26 17:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 2803/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:05\n",
            "\u001b[32m[11/26 17:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 2819/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:12:00\n",
            "\u001b[32m[11/26 17:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 2834/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:11:55\n",
            "\u001b[32m[11/26 17:20:41 d2.evaluation.evaluator]: \u001b[0mInference done 2849/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:11:50\n",
            "\u001b[32m[11/26 17:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 2865/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:11:45\n",
            "\u001b[32m[11/26 17:20:51 d2.evaluation.evaluator]: \u001b[0mInference done 2880/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:11:40\n",
            "\u001b[32m[11/26 17:20:56 d2.evaluation.evaluator]: \u001b[0mInference done 2896/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:11:35\n",
            "\u001b[32m[11/26 17:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 2912/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:11:30\n",
            "\u001b[32m[11/26 17:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 2928/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:11:24\n",
            "\u001b[32m[11/26 17:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 2944/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:11:19\n",
            "\u001b[32m[11/26 17:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 2960/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:11:14\n",
            "\u001b[32m[11/26 17:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 2975/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:11:09\n",
            "\u001b[32m[11/26 17:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 2991/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:11:03\n",
            "\u001b[32m[11/26 17:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 3006/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:10:58\n",
            "\u001b[32m[11/26 17:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 3021/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:10:54\n",
            "\u001b[32m[11/26 17:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 3037/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:10:48\n",
            "\u001b[32m[11/26 17:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 3052/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:43\n",
            "\u001b[32m[11/26 17:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 3067/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:39\n",
            "\u001b[32m[11/26 17:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 3083/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:33\n",
            "\u001b[32m[11/26 17:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 3099/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:28\n",
            "\u001b[32m[11/26 17:22:09 d2.evaluation.evaluator]: \u001b[0mInference done 3115/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:23\n",
            "\u001b[32m[11/26 17:22:14 d2.evaluation.evaluator]: \u001b[0mInference done 3130/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:18\n",
            "\u001b[32m[11/26 17:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 3146/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:12\n",
            "\u001b[32m[11/26 17:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 3162/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:07\n",
            "\u001b[32m[11/26 17:22:30 d2.evaluation.evaluator]: \u001b[0mInference done 3178/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:10:02\n",
            "\u001b[32m[11/26 17:22:35 d2.evaluation.evaluator]: \u001b[0mInference done 3194/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:57\n",
            "\u001b[32m[11/26 17:22:40 d2.evaluation.evaluator]: \u001b[0mInference done 3210/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:51\n",
            "\u001b[32m[11/26 17:22:45 d2.evaluation.evaluator]: \u001b[0mInference done 3226/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:46\n",
            "\u001b[32m[11/26 17:22:51 d2.evaluation.evaluator]: \u001b[0mInference done 3242/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:41\n",
            "\u001b[32m[11/26 17:22:56 d2.evaluation.evaluator]: \u001b[0mInference done 3258/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:35\n",
            "\u001b[32m[11/26 17:23:01 d2.evaluation.evaluator]: \u001b[0mInference done 3274/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:30\n",
            "\u001b[32m[11/26 17:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 3289/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:09:25\n",
            "\u001b[32m[11/26 17:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 3305/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:09:20\n",
            "\u001b[32m[11/26 17:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 3321/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:09:15\n",
            "\u001b[32m[11/26 17:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 3337/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:09\n",
            "\u001b[32m[11/26 17:23:28 d2.evaluation.evaluator]: \u001b[0mInference done 3353/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:09:04\n",
            "\u001b[32m[11/26 17:23:33 d2.evaluation.evaluator]: \u001b[0mInference done 3368/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:59\n",
            "\u001b[32m[11/26 17:23:38 d2.evaluation.evaluator]: \u001b[0mInference done 3384/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:54\n",
            "\u001b[32m[11/26 17:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 3400/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:48\n",
            "\u001b[32m[11/26 17:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 3416/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:43\n",
            "\u001b[32m[11/26 17:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 3431/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:38\n",
            "\u001b[32m[11/26 17:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 3447/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:33\n",
            "\u001b[32m[11/26 17:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 3462/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:28\n",
            "\u001b[32m[11/26 17:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 3478/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:23\n",
            "\u001b[32m[11/26 17:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 3494/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:17\n",
            "\u001b[32m[11/26 17:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 3510/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:12\n",
            "\u001b[32m[11/26 17:24:25 d2.evaluation.evaluator]: \u001b[0mInference done 3526/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:07\n",
            "\u001b[32m[11/26 17:24:30 d2.evaluation.evaluator]: \u001b[0mInference done 3542/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:08:02\n",
            "\u001b[32m[11/26 17:24:35 d2.evaluation.evaluator]: \u001b[0mInference done 3558/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:56\n",
            "\u001b[32m[11/26 17:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 3573/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:51\n",
            "\u001b[32m[11/26 17:24:46 d2.evaluation.evaluator]: \u001b[0mInference done 3589/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:46\n",
            "\u001b[32m[11/26 17:24:51 d2.evaluation.evaluator]: \u001b[0mInference done 3605/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:41\n",
            "\u001b[32m[11/26 17:24:56 d2.evaluation.evaluator]: \u001b[0mInference done 3621/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:35\n",
            "\u001b[32m[11/26 17:25:01 d2.evaluation.evaluator]: \u001b[0mInference done 3636/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:30\n",
            "\u001b[32m[11/26 17:25:06 d2.evaluation.evaluator]: \u001b[0mInference done 3652/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:25\n",
            "\u001b[32m[11/26 17:25:12 d2.evaluation.evaluator]: \u001b[0mInference done 3668/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:20\n",
            "\u001b[32m[11/26 17:25:17 d2.evaluation.evaluator]: \u001b[0mInference done 3684/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:15\n",
            "\u001b[32m[11/26 17:25:22 d2.evaluation.evaluator]: \u001b[0mInference done 3699/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:10\n",
            "\u001b[32m[11/26 17:25:27 d2.evaluation.evaluator]: \u001b[0mInference done 3715/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:07:04\n",
            "\u001b[32m[11/26 17:25:32 d2.evaluation.evaluator]: \u001b[0mInference done 3730/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:59\n",
            "\u001b[32m[11/26 17:25:37 d2.evaluation.evaluator]: \u001b[0mInference done 3746/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:54\n",
            "\u001b[32m[11/26 17:25:43 d2.evaluation.evaluator]: \u001b[0mInference done 3762/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:49\n",
            "\u001b[32m[11/26 17:25:48 d2.evaluation.evaluator]: \u001b[0mInference done 3778/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:44\n",
            "\u001b[32m[11/26 17:25:53 d2.evaluation.evaluator]: \u001b[0mInference done 3793/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:39\n",
            "\u001b[32m[11/26 17:25:58 d2.evaluation.evaluator]: \u001b[0mInference done 3809/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:33\n",
            "\u001b[32m[11/26 17:26:04 d2.evaluation.evaluator]: \u001b[0mInference done 3825/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:28\n",
            "\u001b[32m[11/26 17:26:09 d2.evaluation.evaluator]: \u001b[0mInference done 3840/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:06:23\n",
            "\u001b[32m[11/26 17:26:14 d2.evaluation.evaluator]: \u001b[0mInference done 3856/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:06:18\n",
            "\u001b[32m[11/26 17:26:19 d2.evaluation.evaluator]: \u001b[0mInference done 3872/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:12\n",
            "\u001b[32m[11/26 17:26:25 d2.evaluation.evaluator]: \u001b[0mInference done 3888/5000. Dataloading: 0.0027 s/iter. Inference: 0.3275 s/iter. Eval: 0.0003 s/iter. Total: 0.3307 s/iter. ETA=0:06:07\n",
            "\u001b[32m[11/26 17:26:30 d2.evaluation.evaluator]: \u001b[0mInference done 3904/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:06:02\n",
            "\u001b[32m[11/26 17:26:35 d2.evaluation.evaluator]: \u001b[0mInference done 3919/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:05:57\n",
            "\u001b[32m[11/26 17:26:40 d2.evaluation.evaluator]: \u001b[0mInference done 3935/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:05:52\n",
            "\u001b[32m[11/26 17:26:45 d2.evaluation.evaluator]: \u001b[0mInference done 3951/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:05:46\n",
            "\u001b[32m[11/26 17:26:50 d2.evaluation.evaluator]: \u001b[0mInference done 3967/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:05:41\n",
            "\u001b[32m[11/26 17:26:56 d2.evaluation.evaluator]: \u001b[0mInference done 3983/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:05:36\n",
            "\u001b[32m[11/26 17:27:01 d2.evaluation.evaluator]: \u001b[0mInference done 3999/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:05:30\n",
            "\u001b[32m[11/26 17:27:06 d2.evaluation.evaluator]: \u001b[0mInference done 4015/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:05:25\n",
            "\u001b[32m[11/26 17:27:11 d2.evaluation.evaluator]: \u001b[0mInference done 4031/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:05:20\n",
            "\u001b[32m[11/26 17:27:17 d2.evaluation.evaluator]: \u001b[0mInference done 4047/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:05:15\n",
            "\u001b[32m[11/26 17:27:22 d2.evaluation.evaluator]: \u001b[0mInference done 4063/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:05:09\n",
            "\u001b[32m[11/26 17:27:27 d2.evaluation.evaluator]: \u001b[0mInference done 4079/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:05:04\n",
            "\u001b[32m[11/26 17:27:32 d2.evaluation.evaluator]: \u001b[0mInference done 4094/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:59\n",
            "\u001b[32m[11/26 17:27:37 d2.evaluation.evaluator]: \u001b[0mInference done 4110/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:54\n",
            "\u001b[32m[11/26 17:27:42 d2.evaluation.evaluator]: \u001b[0mInference done 4125/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:49\n",
            "\u001b[32m[11/26 17:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 4140/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:04:44\n",
            "\u001b[32m[11/26 17:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 4156/5000. Dataloading: 0.0027 s/iter. Inference: 0.3274 s/iter. Eval: 0.0003 s/iter. Total: 0.3306 s/iter. ETA=0:04:38\n",
            "\u001b[32m[11/26 17:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 4172/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:33\n",
            "\u001b[32m[11/26 17:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 4188/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:28\n",
            "\u001b[32m[11/26 17:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 4204/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:23\n",
            "\u001b[32m[11/26 17:28:14 d2.evaluation.evaluator]: \u001b[0mInference done 4220/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:17\n",
            "\u001b[32m[11/26 17:28:19 d2.evaluation.evaluator]: \u001b[0mInference done 4236/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:12\n",
            "\u001b[32m[11/26 17:28:24 d2.evaluation.evaluator]: \u001b[0mInference done 4252/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3305 s/iter. ETA=0:04:07\n",
            "\u001b[32m[11/26 17:28:29 d2.evaluation.evaluator]: \u001b[0mInference done 4268/5000. Dataloading: 0.0027 s/iter. Inference: 0.3273 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:04:01\n",
            "\u001b[32m[11/26 17:28:34 d2.evaluation.evaluator]: \u001b[0mInference done 4284/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:56\n",
            "\u001b[32m[11/26 17:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 4299/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:51\n",
            "\u001b[32m[11/26 17:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 4315/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:46\n",
            "\u001b[32m[11/26 17:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 4331/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:41\n",
            "\u001b[32m[11/26 17:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 4347/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:35\n",
            "\u001b[32m[11/26 17:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 4363/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:30\n",
            "\u001b[32m[11/26 17:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 4379/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:25\n",
            "\u001b[32m[11/26 17:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 4395/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:19\n",
            "\u001b[32m[11/26 17:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 4411/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:14\n",
            "\u001b[32m[11/26 17:29:22 d2.evaluation.evaluator]: \u001b[0mInference done 4427/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:09\n",
            "\u001b[32m[11/26 17:29:27 d2.evaluation.evaluator]: \u001b[0mInference done 4443/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:03:04\n",
            "\u001b[32m[11/26 17:29:32 d2.evaluation.evaluator]: \u001b[0mInference done 4458/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:59\n",
            "\u001b[32m[11/26 17:29:37 d2.evaluation.evaluator]: \u001b[0mInference done 4474/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:53\n",
            "\u001b[32m[11/26 17:29:42 d2.evaluation.evaluator]: \u001b[0mInference done 4490/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:02:48\n",
            "\u001b[32m[11/26 17:29:47 d2.evaluation.evaluator]: \u001b[0mInference done 4505/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:43\n",
            "\u001b[32m[11/26 17:29:53 d2.evaluation.evaluator]: \u001b[0mInference done 4521/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:38\n",
            "\u001b[32m[11/26 17:29:58 d2.evaluation.evaluator]: \u001b[0mInference done 4537/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:32\n",
            "\u001b[32m[11/26 17:30:03 d2.evaluation.evaluator]: \u001b[0mInference done 4553/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:27\n",
            "\u001b[32m[11/26 17:30:08 d2.evaluation.evaluator]: \u001b[0mInference done 4568/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:22\n",
            "\u001b[32m[11/26 17:30:13 d2.evaluation.evaluator]: \u001b[0mInference done 4584/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:17\n",
            "\u001b[32m[11/26 17:30:18 d2.evaluation.evaluator]: \u001b[0mInference done 4599/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:12\n",
            "\u001b[32m[11/26 17:30:24 d2.evaluation.evaluator]: \u001b[0mInference done 4615/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:07\n",
            "\u001b[32m[11/26 17:30:29 d2.evaluation.evaluator]: \u001b[0mInference done 4630/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:02:02\n",
            "\u001b[32m[11/26 17:30:34 d2.evaluation.evaluator]: \u001b[0mInference done 4646/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:56\n",
            "\u001b[32m[11/26 17:30:39 d2.evaluation.evaluator]: \u001b[0mInference done 4662/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:51\n",
            "\u001b[32m[11/26 17:30:44 d2.evaluation.evaluator]: \u001b[0mInference done 4678/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:01:46\n",
            "\u001b[32m[11/26 17:30:49 d2.evaluation.evaluator]: \u001b[0mInference done 4693/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:01:41\n",
            "\u001b[32m[11/26 17:30:55 d2.evaluation.evaluator]: \u001b[0mInference done 4709/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:01:36\n",
            "\u001b[32m[11/26 17:31:00 d2.evaluation.evaluator]: \u001b[0mInference done 4725/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:01:30\n",
            "\u001b[32m[11/26 17:31:05 d2.evaluation.evaluator]: \u001b[0mInference done 4740/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:25\n",
            "\u001b[32m[11/26 17:31:10 d2.evaluation.evaluator]: \u001b[0mInference done 4756/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:20\n",
            "\u001b[32m[11/26 17:31:15 d2.evaluation.evaluator]: \u001b[0mInference done 4772/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:15\n",
            "\u001b[32m[11/26 17:31:21 d2.evaluation.evaluator]: \u001b[0mInference done 4787/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:10\n",
            "\u001b[32m[11/26 17:31:26 d2.evaluation.evaluator]: \u001b[0mInference done 4802/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:05\n",
            "\u001b[32m[11/26 17:31:31 d2.evaluation.evaluator]: \u001b[0mInference done 4818/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:01:00\n",
            "\u001b[32m[11/26 17:31:36 d2.evaluation.evaluator]: \u001b[0mInference done 4835/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:00:54\n",
            "\u001b[32m[11/26 17:31:41 d2.evaluation.evaluator]: \u001b[0mInference done 4850/5000. Dataloading: 0.0027 s/iter. Inference: 0.3271 s/iter. Eval: 0.0003 s/iter. Total: 0.3303 s/iter. ETA=0:00:49\n",
            "\u001b[32m[11/26 17:31:46 d2.evaluation.evaluator]: \u001b[0mInference done 4865/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:44\n",
            "\u001b[32m[11/26 17:31:51 d2.evaluation.evaluator]: \u001b[0mInference done 4880/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:39\n",
            "\u001b[32m[11/26 17:31:56 d2.evaluation.evaluator]: \u001b[0mInference done 4895/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:34\n",
            "\u001b[32m[11/26 17:32:02 d2.evaluation.evaluator]: \u001b[0mInference done 4911/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:29\n",
            "\u001b[32m[11/26 17:32:07 d2.evaluation.evaluator]: \u001b[0mInference done 4927/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:24\n",
            "\u001b[32m[11/26 17:32:12 d2.evaluation.evaluator]: \u001b[0mInference done 4943/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:18\n",
            "\u001b[32m[11/26 17:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 4958/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:13\n",
            "\u001b[32m[11/26 17:32:23 d2.evaluation.evaluator]: \u001b[0mInference done 4974/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:08\n",
            "\u001b[32m[11/26 17:32:28 d2.evaluation.evaluator]: \u001b[0mInference done 4989/5000. Dataloading: 0.0027 s/iter. Inference: 0.3272 s/iter. Eval: 0.0003 s/iter. Total: 0.3304 s/iter. ETA=0:00:03\n",
            "\u001b[32m[11/26 17:32:31 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:27:30.552785 (0.330441 s / iter per device, on 1 devices)\n",
            "\u001b[32m[11/26 17:32:31 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:27:14 (0.327227 s / iter per device, on 1 devices)\n",
            "\u001b[32m[11/26 17:32:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
            "\u001b[32m[11/26 17:32:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
            "\u001b[32m[11/26 17:32:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
            "Loading and preparing results...\n",
            "DONE (t=0.06s)\n",
            "creating index...\n",
            "index created!\n",
            "\u001b[32m[11/26 17:32:32 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
            "\u001b[32m[11/26 17:32:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 8.58 seconds.\n",
            "\u001b[32m[11/26 17:32:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
            "\u001b[32m[11/26 17:32:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.81 seconds.\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.483\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.376\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.454\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.272\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.384\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.422\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.526\n",
            "\u001b[32m[11/26 17:32:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
            "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
            "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
            "| 33.364 | 48.260 | 37.624 | 16.168 | 36.883 | 45.436 |\n",
            "\u001b[32m[11/26 17:32:41 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
            "| category      | AP     | category     | AP     | category       | AP     |\n",
            "|:--------------|:-------|:-------------|:-------|:---------------|:-------|\n",
            "| person        | 47.601 | bicycle      | 24.741 | car            | 37.545 |\n",
            "| motorcycle    | 34.906 | airplane     | 59.284 | bus            | 58.547 |\n",
            "| train         | 52.196 | truck        | 19.117 | boat           | 20.660 |\n",
            "| traffic light | 22.095 | fire hydrant | 59.682 | stop sign      | 61.611 |\n",
            "| parking meter | 40.450 | bench        | 17.085 | bird           | 28.204 |\n",
            "| cat           | 57.597 | dog          | 52.428 | horse          | 49.259 |\n",
            "| sheep         | 38.968 | cow          | 46.911 | elephant       | 54.481 |\n",
            "| bear          | 59.376 | zebra        | 61.474 | giraffe        | 63.286 |\n",
            "| backpack      | 8.189  | umbrella     | 29.745 | handbag        | 8.151  |\n",
            "| tie           | 28.521 | suitcase     | 26.897 | frisbee        | 55.308 |\n",
            "| skis          | 16.652 | snowboard    | 29.594 | sports ball    | 43.725 |\n",
            "| kite          | 34.746 | baseball bat | 22.714 | baseball glove | 29.721 |\n",
            "| skateboard    | 46.012 | surfboard    | 31.481 | tennis racket  | 39.918 |\n",
            "| bottle        | 32.007 | wine glass   | 29.371 | cup            | 31.796 |\n",
            "| fork          | 23.484 | knife        | 10.714 | spoon          | 11.655 |\n",
            "| bowl          | 31.655 | banana       | 15.125 | apple          | 10.764 |\n",
            "| sandwich      | 23.863 | orange       | 21.334 | broccoli       | 13.604 |\n",
            "| carrot        | 13.605 | hot dog      | 22.263 | pizza          | 45.940 |\n",
            "| donut         | 31.937 | cake         | 26.239 | chair          | 18.252 |\n",
            "| couch         | 29.568 | potted plant | 18.025 | bed            | 29.926 |\n",
            "| dining table  | 18.633 | toilet       | 50.810 | tv             | 48.753 |\n",
            "| laptop        | 53.770 | mouse        | 55.328 | remote         | 23.620 |\n",
            "| keyboard      | 42.199 | cell phone   | 26.975 | microwave      | 46.307 |\n",
            "| oven          | 25.440 | toaster      | 31.617 | sink           | 31.448 |\n",
            "| refrigerator  | 49.208 | book         | 6.284  | clock          | 42.793 |\n",
            "| vase          | 30.843 | scissors     | 16.337 | teddy bear     | 39.987 |\n",
            "| hair drier    | 0.000  | toothbrush   | 18.775 |                |        |\n",
            "OrderedDict([('bbox', {'AP': 33.364150943521835, 'AP50': 48.25995771208579, 'AP75': 37.62413012012617, 'APs': 16.167744353026134, 'APm': 36.882614884363086, 'APl': 45.43618623691052, 'AP-person': 47.601171990126744, 'AP-bicycle': 24.74051181906249, 'AP-car': 37.54539010545497, 'AP-motorcycle': 34.9056920624446, 'AP-airplane': 59.28444203611348, 'AP-bus': 58.5466719701549, 'AP-train': 52.1957684625786, 'AP-truck': 19.11679303730594, 'AP-boat': 20.65981279564369, 'AP-traffic light': 22.09499365544799, 'AP-fire hydrant': 59.68226526836451, 'AP-stop sign': 61.61109857583595, 'AP-parking meter': 40.44996528881814, 'AP-bench': 17.08521285239361, 'AP-bird': 28.20396885143399, 'AP-cat': 57.59736747515127, 'AP-dog': 52.42770653045922, 'AP-horse': 49.25909517718043, 'AP-sheep': 38.96801987993614, 'AP-cow': 46.910780725784576, 'AP-elephant': 54.48070354840002, 'AP-bear': 59.37556182246719, 'AP-zebra': 61.473979905905196, 'AP-giraffe': 63.28648674417134, 'AP-backpack': 8.188868195351905, 'AP-umbrella': 29.74538271687459, 'AP-handbag': 8.15118064454768, 'AP-tie': 28.521086086274494, 'AP-suitcase': 26.896728461584686, 'AP-frisbee': 55.30786782876469, 'AP-skis': 16.652085431749406, 'AP-snowboard': 29.593836009280892, 'AP-sports ball': 43.72452467811085, 'AP-kite': 34.74621386488285, 'AP-baseball bat': 22.71368172140601, 'AP-baseball glove': 29.720539776704303, 'AP-skateboard': 46.012052946913435, 'AP-surfboard': 31.480744936930392, 'AP-tennis racket': 39.9184266365398, 'AP-bottle': 32.00707877502425, 'AP-wine glass': 29.371290754738105, 'AP-cup': 31.79630783225935, 'AP-fork': 23.48449618778367, 'AP-knife': 10.714444041085544, 'AP-spoon': 11.654719051659649, 'AP-bowl': 31.654957740873353, 'AP-banana': 15.125287147890113, 'AP-apple': 10.764455268807414, 'AP-sandwich': 23.86348715751396, 'AP-orange': 21.33394055701882, 'AP-broccoli': 13.604480585774855, 'AP-carrot': 13.605048649244408, 'AP-hot dog': 22.26275493715765, 'AP-pizza': 45.93989830904281, 'AP-donut': 31.93678689133258, 'AP-cake': 26.23859949114361, 'AP-chair': 18.252365129574052, 'AP-couch': 29.56750285398641, 'AP-potted plant': 18.02513339844328, 'AP-bed': 29.925942966524065, 'AP-dining table': 18.63344242504934, 'AP-toilet': 50.80997227068483, 'AP-tv': 48.75301502538803, 'AP-laptop': 53.76994648687332, 'AP-mouse': 55.327927501159145, 'AP-remote': 23.619942976692503, 'AP-keyboard': 42.19924150620326, 'AP-cell phone': 26.974845280297515, 'AP-microwave': 46.3072638079421, 'AP-oven': 25.43968656927612, 'AP-toaster': 31.617161716171616, 'AP-sink': 31.448425393236114, 'AP-refrigerator': 49.208305654351754, 'AP-book': 6.283959578525991, 'AP-clock': 42.792509662758995, 'AP-vase': 30.8426455318463, 'AP-scissors': 16.33663366336634, 'AP-teddy bear': 39.986794785437, 'AP-hair drier': 0.0, 'AP-toothbrush': 18.77469740305776})])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrSQN8IPNSlP"
      },
      "source": [
        "# SSD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiCpABpFNxV8"
      },
      "source": [
        "## Import some libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2-21kLMNZqS"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from PIL import Image, ImageFile\n",
        "import zipfile"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY_5Wrl2QMPg"
      },
      "source": [
        "## Install Coco API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "G_5aWPviQB-u",
        "outputId": "9f4751c5-fd9f-4537-e016-ca1671856793"
      },
      "source": [
        "pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/philferriere/cocoapi.git to /tmp/pip-req-build-8emdajx2\n",
            "  Running command git clone -q https://github.com/philferriere/cocoapi.git /tmp/pip-req-build-8emdajx2\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp37-cp37m-linux_x86_64.whl size=264143 sha256=62953e0e766dd3518ad6d9fc0001322508ed5d1cd9f8ba5286aac4dd7eea5160\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3udcs31f/wheels/6b/c6/c5/cb6da4cb793a6cb1ab91f6578d76c42686422127eb4dbcea94\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.2\n",
            "    Uninstalling pycocotools-2.0.2:\n",
            "      Successfully uninstalled pycocotools-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "detectron2 0.6+cu111 requires pycocotools>=2.0.2, but you have pycocotools 2.0 which is incompatible.\u001b[0m\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pycocotools"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRnQoM5lQw1v",
        "outputId": "3536e203-1cea-4bdb-8ffc-7a32c30885d1"
      },
      "source": [
        "pip install pycocotools"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RxrHAqzQZFg"
      },
      "source": [
        "## Pre procassing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdeei9GJQdeD"
      },
      "source": [
        "data = \"/content/val2017\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEWt3d-dQh7o"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((400,400)),    \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                    std=[0.229, 0.224, 0.225] )\n",
        "    ])\n",
        "batch_size=20"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-hvimZxQmz3"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obHXqul1Qp1m",
        "outputId": "7424e3c8-027d-44ca-a997-5fe82070a305"
      },
      "source": [
        "test_data = torchvision.datasets.CocoDetection(data,\"/content/annotations/instances_val2017.json\",transform=transform)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.84s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otrb9UZYQr43"
      },
      "source": [
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=64, collate_fn=collate_fn)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTEh9-IpRVee"
      },
      "source": [
        "## Download the model and validate it on dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziiTXdmpRTPK"
      },
      "source": [
        "SSD = torchvision.models.detection.ssd300_vgg16(pretrained=True)\n",
        "SSD.eval()\n",
        "x = [torch.rand(3, 300, 300), torch.rand(3, 500, 400)]\n",
        "predictionsSSD = SSD(x)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBJQ_UetWg68"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\") \n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCsKqbo-Rjjm"
      },
      "source": [
        "for batch in testloader:\n",
        "  inputs, targets = batch\n",
        "  inputs = inputs[1].to(device)\n",
        "  output = predictionsSSD"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9MSBjcKRlVX"
      },
      "source": [
        "## Study predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNqnY-7uW9BH"
      },
      "source": [
        "boxes (FloatTensor[N, 4]): the predicted boxes in [x1, y1, x2, y2] format, with 0 <= x1 < x2 <= W and 0 <= y1 < y2 <= H.\n",
        "\n",
        "labels (Int64Tensor[N]): the predicted labels for each detection\n",
        "\n",
        "scores (Tensor[N]): the scores for each detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsDCEB0LRkmO",
        "outputId": "8f185764-9f9a-4b32-c496-53299c07aae0"
      },
      "source": [
        "predictionsSSD"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'boxes': tensor([[ 67.9313,   2.3697, 255.0805, 179.3450],\n",
              "          [ 70.1910,   1.6638, 222.7966,  89.3027],\n",
              "          [ 39.1785,   5.3961, 115.3067, 155.9398],\n",
              "          [  6.3562,  20.9728,  83.6169, 200.1223],\n",
              "          [103.3574,  39.4626, 218.0388, 273.1003],\n",
              "          [  9.4098,   1.6629, 152.5855,  92.7701],\n",
              "          [ 28.8267,   0.0000, 145.2865, 220.9718],\n",
              "          [ 69.8480,  10.5413, 154.1235, 145.3918],\n",
              "          [107.2577,   6.3449, 181.2944, 158.6008],\n",
              "          [  1.5354,   1.6396, 299.8727, 292.3865],\n",
              "          [132.9502,   9.9965, 219.6029, 145.3501],\n",
              "          [115.9080,  18.8337, 189.8596,  93.8772],\n",
              "          [ 44.1532,  61.3865, 112.9935, 220.7560],\n",
              "          [ 79.7251,  33.1362, 213.6867, 119.4597],\n",
              "          [  0.0000,  45.8275, 117.2950, 268.8766],\n",
              "          [142.8425,  55.5459, 300.0000, 259.3199],\n",
              "          [169.5291,   3.5140, 245.6282, 157.3768],\n",
              "          [ 84.6675,  18.6952, 157.5719,  93.7868],\n",
              "          [ 31.3205,  17.3290, 108.8149,  94.5086],\n",
              "          [  1.6283,   3.0061,  80.2464,  81.8926],\n",
              "          [  5.3461,   1.6470, 294.1503, 294.6296],\n",
              "          [144.7194,   4.4477, 225.1168,  77.4407],\n",
              "          [ 49.9801,  71.3146, 173.6313, 207.4057],\n",
              "          [141.9865,   0.4951, 288.9706,  91.9027],\n",
              "          [ 37.6124,   8.7263,  74.3469,  71.9558],\n",
              "          [206.2357,  55.0951, 281.8282, 232.6336],\n",
              "          [ 20.6867,   7.7039,  58.6395,  72.8996],\n",
              "          [224.1271,   1.8103, 299.7315,  80.4969],\n",
              "          [ 10.7332,   0.0000, 291.3560, 296.0793],\n",
              "          [ 54.3579,   9.5449,  89.8459,  71.6036],\n",
              "          [  6.0218, 123.3237,  83.3982, 290.2109],\n",
              "          [ 74.2269,  85.5581, 101.9338, 159.0493],\n",
              "          [ 58.5299,  85.6757,  86.3618, 158.9538],\n",
              "          [178.5397,  19.5380, 256.2221,  93.7146],\n",
              "          [147.4631,  34.5726, 221.6592, 108.5172],\n",
              "          [102.2404,  84.0994, 171.3564, 157.2843],\n",
              "          [ 89.9377,  85.5956, 117.9737, 159.0184],\n",
              "          [ 35.3372,  99.2864, 107.7449, 174.1302],\n",
              "          [202.8035,   0.9787, 288.5807, 161.2137],\n",
              "          [ 85.3637,  69.5191, 210.5414, 152.9514],\n",
              "          [ 41.8652,  85.4124,  70.0467, 158.5840],\n",
              "          [218.0864,  85.0077, 245.5253, 158.1595],\n",
              "          [105.7395,  85.5886, 134.0105, 159.1065],\n",
              "          [173.3419,  59.6979, 240.7313, 224.3907],\n",
              "          [ 51.1661,  34.6719, 124.3131, 109.6979],\n",
              "          [ 70.6543,  26.5675, 105.3529,  87.8266],\n",
              "          [ 82.8927,  14.2519,  86.9401,  20.1064],\n",
              "          [  7.0670,   3.4027,  37.2472,  84.2804],\n",
              "          [ 58.5055, 116.0785,  86.3602, 190.9182],\n",
              "          [237.7966,  85.0681, 299.8622, 268.1751],\n",
              "          [ 13.2764,  67.1988, 141.9740, 154.3198],\n",
              "          [ 86.6502,  99.2291, 155.1083, 173.8732],\n",
              "          [118.3577,  26.4287, 154.2451,  86.9089],\n",
              "          [ 52.0894,  84.5014, 122.9582, 158.2373],\n",
              "          [ 74.3857, 116.0992, 101.9384, 190.6384],\n",
              "          [201.9850,  84.6527, 229.4156, 158.5555],\n",
              "          [121.7136,  85.5463, 150.2024, 158.8301],\n",
              "          [ 41.9370,  35.2940,  70.1046, 110.3640],\n",
              "          [218.0566, 116.1571, 245.4984, 190.5216],\n",
              "          [ 84.6381,  12.4235,  88.3540,  16.9018],\n",
              "          [ 85.9326,  51.5832, 156.2699, 124.3415],\n",
              "          [ 42.9038, 127.5141, 113.8959, 287.1530],\n",
              "          [ 86.6922,  26.9777, 121.8322,  87.4628],\n",
              "          [ 58.3421,  35.9200,  86.2154, 109.9441],\n",
              "          [  1.5354,   1.6396, 299.8727, 292.3865],\n",
              "          [ 41.7664, 115.8469,  70.0079, 190.9024],\n",
              "          [116.6462,  51.4099, 188.6274, 124.0902],\n",
              "          [102.2570,  26.6513, 137.9806,  87.0217],\n",
              "          [134.1367,  26.3926, 170.0844,  87.0308],\n",
              "          [ 48.8033,  95.5842, 277.1176, 225.3721],\n",
              "          [ 18.7571, 115.0213,  91.8739, 190.2075],\n",
              "          [153.3951,  20.1377, 182.4593,  94.5757],\n",
              "          [  4.9592,  39.9901, 165.3931, 115.4655],\n",
              "          [233.6558,  99.9647, 261.9890, 174.9347],\n",
              "          [ 83.5770,   7.9632,  86.6880,  11.8523],\n",
              "          [246.8840,   7.7074, 283.6490,  72.1124],\n",
              "          [118.0295,  98.9956, 186.7852, 173.7027],\n",
              "          [128.7257,  88.5813, 224.8922, 196.9386],\n",
              "          [ 89.8348,  52.5550, 117.8320, 126.4565],\n",
              "          [218.0299,  20.2432, 245.7782,  95.8540],\n",
              "          [105.6955,  52.0242, 133.8828, 126.1812],\n",
              "          [ 26.0248,  84.8075,  53.7251, 159.3397],\n",
              "          [230.1125,   8.8161, 267.0236,  71.6632],\n",
              "          [130.2263,  40.3100, 293.5821, 116.0633],\n",
              "          [165.8601,  26.5021, 202.2121,  86.9038],\n",
              "          [  5.3461,   1.6470, 294.1503, 294.6296],\n",
              "          [  1.5354,   1.6396, 299.8727, 292.3865],\n",
              "          [  1.5354,   1.6396, 299.8727, 292.3865],\n",
              "          [ 62.0100, 133.5031, 260.3419, 300.0000],\n",
              "          [137.9032, 174.1761, 288.9440, 294.7893],\n",
              "          [ 42.7816, 117.4301, 278.4534, 300.0000]], grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  5,  1,  1,  1,  1,  1,  1,  1, 28,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 65,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 61, 38,  9,  5,  5,\n",
              "          35]),\n",
              "  'scores': tensor([0.0456, 0.0445, 0.0444, 0.0408, 0.0390, 0.0388, 0.0377, 0.0377, 0.0369,\n",
              "          0.0360, 0.0348, 0.0341, 0.0331, 0.0321, 0.0320, 0.0315, 0.0315, 0.0314,\n",
              "          0.0306, 0.0294, 0.0292, 0.0287, 0.0286, 0.0286, 0.0284, 0.0281, 0.0278,\n",
              "          0.0273, 0.0262, 0.0258, 0.0253, 0.0251, 0.0246, 0.0243, 0.0242, 0.0240,\n",
              "          0.0240, 0.0239, 0.0237, 0.0236, 0.0234, 0.0234, 0.0234, 0.0233, 0.0228,\n",
              "          0.0227, 0.0226, 0.0226, 0.0226, 0.0225, 0.0225, 0.0224, 0.0220, 0.0219,\n",
              "          0.0218, 0.0218, 0.0217, 0.0217, 0.0217, 0.0216, 0.0216, 0.0215, 0.0215,\n",
              "          0.0215, 0.0214, 0.0214, 0.0214, 0.0214, 0.0214, 0.0212, 0.0211, 0.0208,\n",
              "          0.0207, 0.0206, 0.0206, 0.0206, 0.0205, 0.0204, 0.0203, 0.0203, 0.0202,\n",
              "          0.0202, 0.0201, 0.0200, 0.0199, 0.0183, 0.0178, 0.0146, 0.0143, 0.0106,\n",
              "          0.0102], grad_fn=<IndexBackward0>)},\n",
              " {'boxes': tensor([[  7.8128,   4.2715, 392.7259, 487.1571],\n",
              "          [ 91.0788,   4.7058, 298.4907, 148.7122],\n",
              "          [ 51.4368,   8.4005, 154.2025, 258.8782],\n",
              "          [144.0894,   9.0888, 340.3680, 242.9735],\n",
              "          [ 10.8185,   3.8861, 205.6812, 153.7496],\n",
              "          [ 91.5982,  18.9799, 206.1680, 240.5571],\n",
              "          [ 13.3336,   0.0000, 389.1078, 489.7073],\n",
              "          [  7.0330,   9.8480, 115.0332, 268.7382],\n",
              "          [102.4831,  54.3696, 284.0955, 197.0178],\n",
              "          [134.0594,  61.1197, 289.7827, 452.7969],\n",
              "          [ 55.9827,  53.2543, 236.6713, 295.6400],\n",
              "          [185.7765,   1.4856, 386.0645, 153.5888],\n",
              "          [  1.6959,  50.1097, 124.1913, 475.9760],\n",
              "          [  3.8939,   6.8317, 397.8062, 481.4508],\n",
              "          [228.9056,  42.9560, 324.1396, 316.2648],\n",
              "          [ 58.8261,  97.1397, 151.1490, 370.8111],\n",
              "          [154.4453,  32.4771, 252.6544, 155.2207],\n",
              "          [  3.8939,   6.8317, 397.8062, 481.4508],\n",
              "          [187.8808,  42.1750, 280.0815, 318.4062],\n",
              "          [197.4568,  32.1917, 295.0071, 154.8972],\n",
              "          [112.2758,  33.1048, 210.2540, 154.9580],\n",
              "          [  2.0988, 139.3510, 133.9798, 337.4103],\n",
              "          [127.0195,  85.6385, 258.1079, 277.5491],\n",
              "          [  3.1619,   6.8314, 107.3786, 134.8953],\n",
              "          [188.6464,  85.1234, 400.0000, 432.0602],\n",
              "          [238.1819,  32.9438, 341.0067, 155.4818],\n",
              "          [ 35.9093,  48.6640, 197.7198, 469.5295],\n",
              "          [ 42.6839,  30.5415, 145.9015, 156.8762],\n",
              "          [273.6932,  32.5244, 378.7760, 326.8509],\n",
              "          [ 50.5446,  15.9903,  99.0059, 119.4219],\n",
              "          [ 27.8908,  14.9044,  77.4859, 119.9733],\n",
              "          [ 72.8762,  16.9177, 119.6185, 118.8516],\n",
              "          [269.2027,  34.5617, 306.4350, 158.9615],\n",
              "          [257.8107,   7.5937, 367.5484, 128.9693],\n",
              "          [317.8425,  77.9471, 399.3916, 399.0034],\n",
              "          [107.0482,  95.9398, 194.3146, 366.7523],\n",
              "          [274.9420, 149.7716, 376.1151, 439.0425],\n",
              "          [218.8078,  58.9686, 315.3582, 180.3168],\n",
              "          [171.7887,  67.1911, 390.1351, 191.0562],\n",
              "          [290.5855,  34.6032, 327.7421, 158.9635],\n",
              "          [314.7097,   0.0000, 400.0000, 230.4811],\n",
              "          [247.6510,  34.1656, 285.8882, 157.7795],\n",
              "          [ 98.7785,  35.2635, 135.5811, 158.4768],\n",
              "          [226.1755,  33.7899, 264.4275, 157.4343],\n",
              "          [  7.2896,  68.2480, 221.0023, 192.0621],\n",
              "          [157.8741,  44.3990, 205.2485, 144.3953],\n",
              "          [200.5323,  44.1092, 247.9360, 144.3753],\n",
              "          [ 17.9312, 112.7273, 194.1979, 255.6575],\n",
              "          [311.0776,   7.1827, 350.1298, 132.9392],\n",
              "          [141.0230,  34.8923, 178.7794, 158.1658],\n",
              "          [119.7754,  35.6531, 157.1309, 158.1173],\n",
              "          [179.3821,  44.2755, 226.5008, 144.4770],\n",
              "          [ 81.6413, 224.2791, 344.9500, 500.0000],\n",
              "          [162.6861, 142.2050, 199.8977, 264.9896],\n",
              "          [111.3321, 174.4663, 279.5669, 306.4982],\n",
              "          [333.4358,   6.3121, 372.3827, 133.1588],\n",
              "          [257.2166,  55.6899, 320.2235, 132.6830],\n",
              "          [  9.4773, 257.2060, 110.9326, 500.0000],\n",
              "          [141.5421, 142.6953, 178.3351, 265.1993],\n",
              "          [291.1524, 140.7608, 327.0151, 264.4560],\n",
              "          [ 88.1712, 135.3306, 309.5113, 241.3535],\n",
              "          [311.7961, 192.0842, 348.6387, 319.2129],\n",
              "          [ 77.9230,  60.7432, 114.7124, 184.2304],\n",
              "          [291.1138, 192.7896, 326.9780, 319.1034],\n",
              "          [ 68.5792,  59.4010, 166.3109, 181.6647],\n",
              "          [  9.7628,   7.5920,  49.6283, 138.4862],\n",
              "          [ 55.7766,  60.0479,  93.3864, 185.0027],\n",
              "          [194.9595, 115.0536, 375.5864, 253.7289],\n",
              "          [ 59.4948, 315.9289, 148.9077, 500.0000],\n",
              "          [135.4167, 141.4577, 228.7922, 260.8197],\n",
              "          [183.8623, 142.1516, 221.1644, 265.2590],\n",
              "          [141.4857,  87.3302, 178.2901, 212.1240],\n",
              "          [311.9999, 139.9350, 348.7200, 265.3350],\n",
              "          [162.6685,  86.8787, 199.7652, 211.4072],\n",
              "          [214.4384,  55.6676, 277.2776, 132.5717],\n",
              "          [ 99.4671, 142.5930, 135.4172, 264.7570],\n",
              "          [204.8781, 142.3708, 242.3711, 265.0097],\n",
              "          [ 78.2351, 142.4769, 114.5705, 264.2379],\n",
              "          [234.8146,  27.1835, 299.4973, 105.6370],\n",
              "          [334.6421, 218.1170, 371.3132, 346.2839],\n",
              "          [334.8059, 165.0278, 371.2062, 294.2529],\n",
              "          [120.3155, 143.0430, 156.9114, 264.8560],\n",
              "          [ 60.7244, 152.8194, 368.9965, 375.9592],\n",
              "          [  3.8939,   6.8317, 397.8062, 481.4508],\n",
              "          [183.8849, 289.6658, 387.8478, 489.5793],\n",
              "          [  3.8939,   6.8317, 397.8062, 481.4508],\n",
              "          [148.9250, 146.9948, 278.5822, 500.0000],\n",
              "          [ 39.6422, 289.5144, 245.5246, 491.1525],\n",
              "          [121.5102, 350.6039, 369.4315, 463.0306],\n",
              "          [101.9512,  95.6377, 325.5854, 416.9769],\n",
              "          [101.9512,  95.6377, 325.5854, 416.9769],\n",
              "          [ 53.9367, 197.2175, 370.7987, 500.0000]], grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([ 5,  1,  1,  1,  1,  1, 28,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 38,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  5,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "           1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 65,  5,  9,  5,  5,  5,  5,\n",
              "          35, 35]),\n",
              "  'scores': tensor([0.0542, 0.0481, 0.0398, 0.0382, 0.0377, 0.0370, 0.0362, 0.0351, 0.0346,\n",
              "          0.0327, 0.0322, 0.0320, 0.0308, 0.0289, 0.0287, 0.0287, 0.0285, 0.0279,\n",
              "          0.0276, 0.0275, 0.0270, 0.0255, 0.0253, 0.0251, 0.0249, 0.0248, 0.0247,\n",
              "          0.0245, 0.0242, 0.0238, 0.0233, 0.0224, 0.0222, 0.0219, 0.0219, 0.0217,\n",
              "          0.0217, 0.0215, 0.0214, 0.0214, 0.0213, 0.0211, 0.0207, 0.0203, 0.0197,\n",
              "          0.0195, 0.0195, 0.0195, 0.0194, 0.0193, 0.0193, 0.0192, 0.0192, 0.0189,\n",
              "          0.0188, 0.0187, 0.0187, 0.0187, 0.0186, 0.0186, 0.0185, 0.0185, 0.0184,\n",
              "          0.0184, 0.0183, 0.0183, 0.0182, 0.0181, 0.0180, 0.0180, 0.0178, 0.0177,\n",
              "          0.0177, 0.0177, 0.0176, 0.0175, 0.0175, 0.0174, 0.0174, 0.0173, 0.0172,\n",
              "          0.0172, 0.0172, 0.0140, 0.0128, 0.0126, 0.0113, 0.0109, 0.0109, 0.0108,\n",
              "          0.0108, 0.0108], grad_fn=<IndexBackward0>)}]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGcit0-VRZ-F"
      },
      "source": [
        "# Retina Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvPB6CC2Rwce"
      },
      "source": [
        "## Download the model and validate it on dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88,
          "referenced_widgets": [
            "4bc74941710541648ae6ce7befc054b2",
            "3e8fa87db26e45f6a3ba37146b03faf4",
            "c7950e8878e34d169d5c7e1b35b7fafb",
            "bf82e0b5a0fb4e7b8da63186111f6da5",
            "a450d2f7cd3f44e3be5ff398c20809b2",
            "9bd12c3d49184364ab0a463112de6215",
            "a4c899ddfc7547668394cbc35d2d50eb",
            "3e7e97d0b57d4dc88e88e8bebf13b148",
            "bb3d287179f24c0a85a513966aaa73d2",
            "9af8201a05e64c0d9a8ea689aea16dea",
            "2308dc125554447eafaf43dffefcf6d8"
          ]
        },
        "id": "KdHae6cURvxk",
        "outputId": "37d04237-c7e2-4fc4-d64c-a408f2edb82f"
      },
      "source": [
        "Retina = torchvision.models.detection.retinanet_resnet50_fpn(pretrained=True)\n",
        "Retina.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictionsRetina = Retina(x)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_coco-eeacb38b.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4bc74941710541648ae6ce7befc054b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/130M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obG_KLqPXaDA"
      },
      "source": [
        "for batch in testloader:\n",
        "  inputs, targets = batch\n",
        "  inputs = inputs[1].to(device)\n",
        "  output = predictionsRetina"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjbml3ZbS4Ev"
      },
      "source": [
        "## Study predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guZxmYACX9N-"
      },
      "source": [
        "boxes (FloatTensor[N, 4]): the predicted boxes in [x1, y1, x2, y2] format, with 0 <= x1 < x2 <= W and 0 <= y1 < y2 <= H.\n",
        "\n",
        "labels (Int64Tensor[N]): the predicted labels for each detection\n",
        "\n",
        "scores (Tensor[N]): the scores of each detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIBDQik1S20x",
        "outputId": "2a3e9426-d13a-4e28-e897-a62b59a7101e"
      },
      "source": [
        "predictionsRetina"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'boxes': tensor([[  0.0000,   2.3714, 400.0000, 295.8163],\n",
              "          [  0.0000,   7.1562, 400.0000, 299.1739],\n",
              "          [  0.8063,   0.0000, 400.0000, 300.0000],\n",
              "          [  0.8063,   0.0000, 400.0000, 300.0000],\n",
              "          [  0.8063,   0.0000, 400.0000, 300.0000],\n",
              "          [  0.8063,   0.0000, 400.0000, 300.0000],\n",
              "          [  0.0000,   2.3714, 400.0000, 295.8163]], grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([72, 28,  9,  7,  3, 65, 64]),\n",
              "  'scores': tensor([0.1348, 0.1051, 0.1036, 0.0859, 0.0725, 0.0641, 0.0606],\n",
              "         grad_fn=<IndexBackward0>)},\n",
              " {'boxes': tensor([[  6.9416,   4.3319, 400.0000, 500.0000],\n",
              "          [  6.9416,   4.3319, 400.0000, 500.0000]], grad_fn=<StackBackward0>),\n",
              "  'labels': tensor([72, 64]),\n",
              "  'scores': tensor([0.0638, 0.0541], grad_fn=<IndexBackward0>)}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7otXolxNYVPf"
      },
      "source": [
        "# Custom IoU function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gWxIRagYUql"
      },
      "source": [
        "SMOOTH = 1e-6\n",
        "\n",
        "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
        "    # You can comment out this line if you are passing tensors of equal shape\n",
        "    # But if you are passing output from UNet or something it will most probably\n",
        "    # be with the BATCH x 1 x H x W shape\n",
        "    outputs = outputs.squeeze(1)  # BATCH x 1 x H x W => BATCH x H x W\n",
        "    \n",
        "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
        "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
        "    \n",
        "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
        "    \n",
        "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
        "    \n",
        "    return thresholded  # Or thresholded.mean() if you are interested in average across the batch"
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}